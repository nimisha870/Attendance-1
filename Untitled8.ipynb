{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMf5HMOkjRaNfOZ/Ai8tg5I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimisha870/Attendance-1/blob/master/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxKZm1HgbdIM",
        "outputId": "914b26de-bc24-434c-ce7f-b1167cd73f8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Class Distribution:\n",
            " Class\n",
            "0    763\n",
            "1      9\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Balanced Class Distribution:\n",
            " Class\n",
            "0    763\n",
            "1    763\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-2e78916dd1ab>:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  clusters = balanced_data.groupby('Time', group_keys=False).apply(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Results:\n",
            "     Sampling1  Sampling2  Sampling3  Sampling4  Sampling5\n",
            "M1   0.921397   0.908297      0.976   0.917031   0.958333\n",
            "M2   1.000000   1.000000      0.976   0.995633   0.958333\n",
            "M3   0.925764   0.917031      0.976   0.943231   0.944444\n",
            "M4   0.982533   0.991266      0.936   0.973799   0.930556\n",
            "M5   0.951965   0.943231      0.976   0.934498   0.958333\n",
            "\n",
            "Best Sampling Technique for Each Model:\n",
            "\n",
            "Model: M1, Best Sampling Technique: Sampling3, Accuracy: 0.9760\n",
            "Model: M2, Best Sampling Technique: Sampling1, Accuracy: 1.0000\n",
            "Model: M3, Best Sampling Technique: Sampling3, Accuracy: 0.9760\n",
            "Model: M4, Best Sampling Technique: Sampling2, Accuracy: 0.9913\n",
            "Model: M5, Best Sampling Technique: Sampling3, Accuracy: 0.9760\n",
            "Results saved to 'sampling_results.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import resample\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\")\n",
        "\n",
        "print(\"Original Class Distribution:\\n\", data['Class'].value_counts())\n",
        "\n",
        "\n",
        "minority_class = data[data['Class'] == 1]\n",
        "majority_class = data[data['Class'] == 0]\n",
        "\n",
        "minority_upsampled = resample(\n",
        "    minority_class,\n",
        "    replace=True,\n",
        "    n_samples=len(majority_class),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "balanced_data = pd.concat([majority_class, minority_upsampled])\n",
        "print(\"\\nBalanced Class Distribution:\\n\", balanced_data['Class'].value_counts())\n",
        "\n",
        "samples = {}\n",
        "\n",
        "samples['Sampling1'] = balanced_data.sample(frac=0.5, random_state=42)\n",
        "\n",
        "\n",
        "samples['Sampling2'], _ = train_test_split(\n",
        "    balanced_data,\n",
        "    test_size=0.5,\n",
        "    stratify=balanced_data['Class'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "clusters = balanced_data.groupby('Time', group_keys=False).apply(\n",
        "    lambda x: x.sample(1, random_state=42)\n",
        ")\n",
        "samples['Sampling3'] = clusters\n",
        "\n",
        "samples['Sampling4'] = pd.concat([\n",
        "    majority_class.sample(frac=0.3, random_state=42),\n",
        "    minority_upsampled.sample(frac=0.7, random_state=42)\n",
        "])\n",
        "\n",
        "\n",
        "samples['Sampling5'] = pd.concat([\n",
        "    majority_class.sample(frac=0.3, random_state=42),\n",
        "    minority_class.sample(frac=1.0, random_state=42)\n",
        "])\n",
        "\n",
        "models = {\n",
        "    'M1': LogisticRegression(max_iter=1000),\n",
        "    'M2': RandomForestClassifier(random_state=42),\n",
        "    'M3': SVC(kernel='linear', random_state=42),\n",
        "    'M4': DecisionTreeClassifier(random_state=42),\n",
        "    'M5': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "\n",
        "def train_and_evaluate(X, y):\n",
        "    results = {}\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        results[name] = accuracy\n",
        "\n",
        "    return results\n",
        "\n",
        "final_results = {}\n",
        "\n",
        "for name, sample in samples.items():\n",
        "\n",
        "    if len(sample['Class'].unique()) < 2:\n",
        "        print(f\"Skipping {name} because it contains only one class.\")\n",
        "        continue\n",
        "\n",
        "    X_sample = sample.drop(columns=['Class'])\n",
        "    y_sample = sample['Class']\n",
        "\n",
        "\n",
        "    results = train_and_evaluate(X_sample, y_sample)\n",
        "    final_results[name] = results\n",
        "\n",
        "final_results_df = pd.DataFrame(final_results)\n",
        "print(\"\\nFinal Results:\\n\", final_results_df)\n",
        "\n",
        "best_sampling_techniques = {}\n",
        "\n",
        "for model in models.keys():\n",
        "\n",
        "    model_accuracies = final_results_df.loc[model]\n",
        "\n",
        "\n",
        "    best_sampling_techniques[model] = model_accuracies.idxmax(), model_accuracies.max()\n",
        "\n",
        "\n",
        "print(\"\\nBest Sampling Technique for Each Model:\\n\")\n",
        "for model, (best_sampling, accuracy) in best_sampling_techniques.items():\n",
        "    print(f\"Model: {model}, Best Sampling Technique: {best_sampling}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "final_results_df.to_csv(\"sampling_results.csv\", index=True)\n",
        "print(\"Results saved to 'sampling_results.csv'\")"
      ]
    }
  ]
}